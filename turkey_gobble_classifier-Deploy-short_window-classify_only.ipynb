{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the required libraries for everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Input\n",
    "from keras.preprocessing import image as keras_image\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.backend import tf as ktf\n",
    "from keras.constraints import maxnorm\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths for input/output\n",
    "\n",
    "data_in = 'E:/CJunk/Turkey_gobble_identification/Darren_Data/test/' #this will be the path to the folder holding the WAV files\n",
    "data_out = 'E:/CJunk/Turkey_gobble_identification/outfiles/' #this will be the path where you want the result files stored\n",
    "audio_out = 'E:/CJunk/Turkey_gobble_identification/Darren_Data/audio_out/' #where should the audio snippets go?\n",
    "\n",
    "model_path = 'E:/CJunk/Turkey_gobble_identification/turkey_classifier/model_16Dec2019_35_epochs.mdl' #where is the model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch version of this function\n",
    "def load_classify_images(infile):\n",
    "    image_size_x = 125\n",
    "    image_size_y = 49\n",
    "    stft_params = {'nperseg':1000, 'noverlap':500}\n",
    "    stft_conversion = stft_params['nperseg'] - stft_params['noverlap']\n",
    "    window_shift_size = 500 #6000 equal 0.25seconds\n",
    "    window_shift_size = int(window_shift_size / stft_conversion) #convert the window shift into stft units\n",
    "    inwav = wavfile.read(infile) #load the raw WAV file\n",
    "    outdata = pd.DataFrame(columns=['Event', 'Start_time', 'End_time', 'Gobble', 'Model_output', 'Min:Sec', 'Start_index', 'End_index', 'Num_windows', 'Begin File'])\n",
    "    infilename = infile.split('/')[-1]\n",
    "    gobble_count = 1\n",
    "    results = []\n",
    "    track_gobble = False\n",
    "    gobble_start = 0\n",
    "    gobble_end = 24000\n",
    "    batch_results = {'start':[], 'end':[], 'result':[]}\n",
    "    img_batch = []\n",
    "    f, t, Zxx = signal.stft(inwav[1], 24000, nperseg=stft_params['nperseg'], noverlap=stft_params['noverlap']) #calculate the short time Fourier transform\n",
    "    Zxx = np.abs(Zxx)[25:150, :]     \n",
    "    \n",
    "    #generate the window slices and run them through the CNN\n",
    "    for image in range(0, int(Zxx.shape[1]), window_shift_size): #go through the WAV file in 1/12th second intervals (2000)\n",
    "#         if image % 10000 == 0:\n",
    "#             print(image)\n",
    "        start_ind = image\n",
    "        end_ind = image + 48\n",
    "        \n",
    "        if end_ind + 48 >= int(Zxx.shape[1]): #reached the end of the WAV file; no more 2s windows available\n",
    "            continue\n",
    "        else:\n",
    "            batch_results['start'].append(start_ind)\n",
    "            batch_results['end'].append(end_ind)\n",
    "            img = Zxx[:, start_ind:start_ind+image_size_y].astype('int16') #slice the resulting array down to the proper size for input into the CNN\n",
    "            img = img.reshape(image_size_x,image_size_y,1) \n",
    "            img = img/255.\n",
    "            img_batch.append(img)\n",
    "            if len(img_batch) == 16:\n",
    "                out = model.predict(np.array(img_batch)) #run the images through the CNN\n",
    "                for indiv_result in out:\n",
    "                    batch_results['result'].append(indiv_result)\n",
    "                img_batch = []\n",
    "    \n",
    "    if len(img_batch) > 0: #pickup the last few windows in case it doesn't end on a clean multiple of 16\n",
    "        out = model.predict(np.array(img_batch)) #run the images through the CNN\n",
    "        for indiv_result in out:\n",
    "            batch_results['result'].append(indiv_result)\n",
    "        img_batch = []\n",
    "        \n",
    "    #aggregate the results of the CNN    \n",
    "    for result in range(len(batch_results['start'])):\n",
    "        start_ind = batch_results['start'][result] * stft_conversion #convert back to WAV files units\n",
    "        end_ind = batch_results['end'][result] * stft_conversion #convert back to WAV files units\n",
    "        out = batch_results['result'][result][0]\n",
    "        #if round(out) == 0 and not track_gobble: #CNN said it's a gobble; start tracking the length of the gobble window\n",
    "        if out < 0.4 and not track_gobble: #CNN said it's a gobble; start tracking the length of the gobble window\n",
    "            track_gobble = True\n",
    "            gobble_start = start_ind\n",
    "            gobble_end = start_ind + 24000\n",
    "            gobble_predict_value = out\n",
    "            num_gobble_windows = 1\n",
    "        #elif round(out) == 0: #CNN said this window is still part of the previous gobble\n",
    "        elif out < 0.5 and track_gobble: #CNN said this window is still part of the previous gobble\n",
    "            #if start_ind > gobble_end:\n",
    "            gobble_end += int(window_shift_size * stft_conversion) #extend the window size of the gobble\n",
    "            gobble_predict_value += out\n",
    "            num_gobble_windows += 1\n",
    "        elif track_gobble == True: #CNN said the current window is no longer a gobble; complete the logging for this gobble\n",
    "            track_gobble = False\n",
    "            if num_gobble_windows > 16 and gobble_predict_value/num_gobble_windows < 0.5: #gobble window must be more than 2 windows AND the average value coming from the CNN less than 0.10\n",
    "                gob_st = (gobble_start/24000) / 60.\n",
    "                min_sec = '{0}:{1:02}'.format(int(gob_st), round(((gob_st) - int(gob_st))*60))\n",
    "                outdata.loc[gobble_count] = [gobble_count, round(gobble_start/24000,2), round(gobble_end/24000,2), 1,\n",
    "                                             round(gobble_predict_value/num_gobble_windows,4), min_sec, gobble_start, gobble_end, num_gobble_windows, infilename] #add the info to the DataFrame\n",
    "                gobble_count += 1\n",
    "                while gobble_end - gobble_start < 96000:\n",
    "                    gobble_start -= 1000\n",
    "                    gobble_end += 1000\n",
    "                    if gobble_start < 0:\n",
    "                        gobble_start = 0\n",
    "                        break\n",
    "                    \n",
    "                outwav = inwav[1][gobble_start:gobble_end]\n",
    "                wavfile.write(audio_out + infilename[:-4] + '_gobble_' + str(gobble_count - 1) + '.wav', 24000, outwav) #write the sound snippet to file\n",
    "        else: #no gobble and it wasn't tracking a gobble\n",
    "            pass \n",
    "        \n",
    "    return outdata, batch_results['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dhenrichs\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learn2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhenrichs\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learn2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhenrichs\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learn2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhenrichs\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learn2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhenrichs\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learn2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhenrichs\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learn2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhenrichs\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learn2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhenrichs\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learn2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\dhenrichs\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learn2\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhenrichs\\AppData\\Local\\Continuum\\anaconda3\\envs\\deep_learn2\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = [x for x in os.listdir(data_in) if x[-3:] == 'wav']\n",
    "\n",
    "for infile in input_files:\n",
    "    predictions, pred_scores = load_classify_images(infile)\n",
    "    predictions.to_csv(data_out, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
